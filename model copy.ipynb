{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be96511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8773c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"clean_shape_to_base.json\", encoding=\"utf-8\") as f:\n",
    "    shape_to_base = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590c9523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma_id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>language</th>\n",
       "      <th>pos_cat</th>\n",
       "      <th>pos</th>\n",
       "      <th>root</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>number</th>\n",
       "      <th>person</th>\n",
       "      <th>gender</th>\n",
       "      <th>voice</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>uninflected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023254710</td>\n",
       "      <td>سَاوِي</td>\n",
       "      <td>عامية</td>\n",
       "      <td>اسم</td>\n",
       "      <td>صفة</td>\n",
       "      <td>س و ي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفرد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مذكر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023254711</td>\n",
       "      <td>رْكِيد</td>\n",
       "      <td>عامية</td>\n",
       "      <td>اسم</td>\n",
       "      <td>اسم</td>\n",
       "      <td>ر ك د</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفرد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مذكر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023254712</td>\n",
       "      <td>دُمَاجٌ</td>\n",
       "      <td>عامية</td>\n",
       "      <td>اسم</td>\n",
       "      <td>اسم</td>\n",
       "      <td>د م ج</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفرد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مذكر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023254713</td>\n",
       "      <td>دَامِرٌ</td>\n",
       "      <td>عامية</td>\n",
       "      <td>اسم</td>\n",
       "      <td>اسم</td>\n",
       "      <td>د م ر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفرد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مذكر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023254714</td>\n",
       "      <td>جَعَارٌ</td>\n",
       "      <td>عامية</td>\n",
       "      <td>اسم</td>\n",
       "      <td>صفة</td>\n",
       "      <td>ج ع ر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مفرد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مذكر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lemma_id    lemma language pos_cat  pos   root augmentation number  \\\n",
       "0  2023254710   سَاوِي    عامية     اسم  صفة  س و ي          NaN   مفرد   \n",
       "1  2023254711   رْكِيد    عامية     اسم  اسم  ر ك د          NaN   مفرد   \n",
       "2  2023254712  دُمَاجٌ    عامية     اسم  اسم  د م ج          NaN   مفرد   \n",
       "3  2023254713  دَامِرٌ    عامية     اسم  اسم  د م ر          NaN   مفرد   \n",
       "4  2023254714  جَعَارٌ    عامية     اسم  صفة  ج ع ر          NaN   مفرد   \n",
       "\n",
       "  person gender voice transitivity uninflected  \n",
       "0    NaN   مذكر   NaN          NaN         NaN  \n",
       "1    NaN   مذكر   NaN          NaN         NaN  \n",
       "2    NaN   مذكر   NaN          NaN         NaN  \n",
       "3    NaN   مذكر   NaN          NaN         NaN  \n",
       "4    NaN   مذكر   NaN          NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/Qabas-dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8bfba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Step 2: Normalize text: remove diacritics and unify character variants\n",
    "def normalize_arabic(text):\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    text = re.sub(r'[\\u064B-\\u0652]', '', text)  # Remove diacritics\n",
    "    text = text.replace('ى', 'ي').replace('ة', 'ه')  # Normalize characters\n",
    "    return text\n",
    "\n",
    "df['lemma'] = df['lemma'].astype(str).apply(normalize_arabic)\n",
    "df['root'] = df['root'].astype(str).apply(normalize_arabic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9265e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter relevant columns for multitask learning\n",
    "columns_to_use = ['lemma', 'pos_cat', 'pos', 'root', 'number', 'gender']\n",
    "df = df[columns_to_use]\n",
    "\n",
    "# Step 4: Drop rows with missing target labels\n",
    "df_cleaned = df.dropna(subset=columns_to_use[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75cf91be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/f02hnxjj1h3b9g17p02rdg700000gn/T/ipykernel_65589/2235846460.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n",
      "/var/folders/vl/f02hnxjj1h3b9g17p02rdg700000gn/T/ipykernel_65589/2235846460.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n",
      "/var/folders/vl/f02hnxjj1h3b9g17p02rdg700000gn/T/ipykernel_65589/2235846460.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n",
      "/var/folders/vl/f02hnxjj1h3b9g17p02rdg700000gn/T/ipykernel_65589/2235846460.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n",
      "/var/folders/vl/f02hnxjj1h3b9g17p02rdg700000gn/T/ipykernel_65589/2235846460.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the columns to encode (targets)\n",
    "target_columns = ['pos_cat', 'pos', 'root', 'number', 'gender']\n",
    "\n",
    "# Create a dictionary to store the encoders and class mappings\n",
    "label_encoders = {}\n",
    "label_classes = {}\n",
    "\n",
    "# Apply label encoding to each target column\n",
    "for column in target_columns:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[column + '_encoded'] = le.fit_transform(df_cleaned[column])\n",
    "    label_encoders[column] = le\n",
    "    label_classes[column] = le.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3524a883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 35710\n",
      "Validation size: 4464\n",
      "Test size: 4464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We'll stratify based on 'pos_cat_encoded' to maintain label distribution\n",
    "stratify_label = df_cleaned['pos_cat_encoded']\n",
    "\n",
    "# Step 1: Train + Temp (Validation + Test)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_cleaned,\n",
    "    test_size=0.2,\n",
    "    stratify=stratify_label,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split Temp into Validation and Test (10% each)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_df['pos_cat_encoded'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Sanity check: print sizes\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Validation size:\", len(val_df))\n",
    "print(\"Test size:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd04d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultitaskArabicModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, max_seq_len,\n",
    "                 num_pos_cat, num_pos, num_root, num_number, num_gender):\n",
    "        super(MultitaskArabicModel, self).__init__()\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim, padding_idx=0)\n",
    "\n",
    "        # BiLSTM Encoder\n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim,\n",
    "                               hidden_size=hidden_dim,\n",
    "                               num_layers=1,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=True)\n",
    "\n",
    "        # Max Pooling (over time dimension)\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Task-specific output heads\n",
    "        self.fc_pos_cat = nn.Linear(hidden_dim * 2, num_pos_cat)\n",
    "        self.fc_pos = nn.Linear(hidden_dim * 2, num_pos)\n",
    "        self.fc_root = nn.Linear(hidden_dim * 2, num_root)\n",
    "        self.fc_number = nn.Linear(hidden_dim * 2, num_number)\n",
    "        self.fc_gender = nn.Linear(hidden_dim * 2, num_gender)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, max_seq_len)\n",
    "        x_embed = self.embedding(x)  # (batch_size, max_seq_len, embedding_dim)\n",
    "        lstm_out, _ = self.encoder(x_embed)  # (batch_size, max_seq_len, hidden_dim * 2)\n",
    "        lstm_out = lstm_out.transpose(1, 2)  # (batch_size, hidden_dim * 2, max_seq_len)\n",
    "        pooled = self.pooling(lstm_out).squeeze(-1)  # (batch_size, hidden_dim * 2)\n",
    "\n",
    "        # Output heads\n",
    "        return {\n",
    "            'pos_cat': self.fc_pos_cat(pooled),\n",
    "            'pos': self.fc_pos(pooled),\n",
    "            'root': self.fc_root(pooled),\n",
    "            'number': self.fc_number(pooled),\n",
    "            'gender': self.fc_gender(pooled)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975ef9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultitaskArabicModel(\n",
    "    vocab_size=48,         # Number of characters in your vocab\n",
    "    embedding_dim=64,      # Size of each character embedding\n",
    "    hidden_dim=128,        # BiLSTM hidden size\n",
    "    max_seq_len=9,         # Max lemma length\n",
    "    num_pos_cat=10,        # Replace with actual class count\n",
    "    num_pos=45,\n",
    "    num_root=500,\n",
    "    num_number=3,\n",
    "    num_gender=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "836fde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitask_loss(outputs, targets, loss_weights=None):\n",
    "    \"\"\"\n",
    "    outputs: dict of model outputs for each task\n",
    "    targets: dict of ground truth labels for each task\n",
    "    loss_weights: dict with weights for each task loss (optional)\n",
    "    \"\"\"\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "\n",
    "    for task in outputs.keys():\n",
    "        task_loss = loss_fn(outputs[task], targets[task])\n",
    "        if loss_weights:\n",
    "            task_loss *= loss_weights.get(task, 1.0)\n",
    "        total_loss += task_loss\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b38aec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# outputs from model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[43mbatch_input\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ground truth labels\u001b[39;00m\n\u001b[1;32m      5\u001b[0m targets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_cat\u001b[39m\u001b[38;5;124m'\u001b[39m: pos_cat_batch,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m: pos_batch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender\u001b[39m\u001b[38;5;124m'\u001b[39m: gender_batch\n\u001b[1;32m     11\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_input' is not defined"
     ]
    }
   ],
   "source": [
    "# outputs from model\n",
    "outputs = model(batch_input)\n",
    "\n",
    "# ground truth labels\n",
    "targets = {\n",
    "    'pos_cat': pos_cat_batch,\n",
    "    'pos': pos_batch,\n",
    "    'root': root_batch,\n",
    "    'number': number_batch,\n",
    "    'gender': gender_batch\n",
    "}\n",
    "\n",
    "# optional: assign more importance to some tasks\n",
    "loss_weights = {\n",
    "    'pos_cat': 1.0,\n",
    "    'pos': 1.0,\n",
    "    'root': 0.8,\n",
    "    'number': 0.6,\n",
    "    'gender': 0.6\n",
    "}\n",
    "\n",
    "loss = multitask_loss(outputs, targets, loss_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76f524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
